apiVersion: machinelearning.seldon.io/v1alpha2
kind: SeldonDeployment
metadata:
  name: mlflow-llm
  namespace: seldon
spec:
  name: llm
  predictors:
  - componentSpecs:
    - spec:
        # We are setting high failureThreshold as installing conda dependencies
        # can take long time and we want to avoid k8s killing the container prematurely
        containers:
        - name: llm
          livenessProbe:
            initialDelaySeconds: 80
            failureThreshold: 200
            periodSeconds: 5
            successThreshold: 1
            httpGet:
              path: /health/ping
              port: http
              scheme: HTTP
          readinessProbe:
            initialDelaySeconds: 80
            failureThreshold: 200
            periodSeconds: 5
            successThreshold: 1
            httpGet:
              path: /health/ping
              port: http
              scheme: HTTP
          resources:
            limits:
              cpu: "2"
              memory: 32Gi
              nvidia.com/gpu: "1"
            requests:
              cpu: "2"
              memory: 32Gi
              nvidia.com/gpu: "1"
          env:
            - name: CMAKE_ARGS
              value: -DLLAMA_CUBLAS=on 
            - name: FORCE_CMAKE
              value: "1"
        tolerations:
        - key: sku
          operator: Equal
          value: gpu
          effect: NoSchedule
    graph:
      children: []
      implementation: MLFLOW_SERVER
      modelUri: azureblob:test/llama-cpp/model
      name: llm
      envSecretRefName: seldon-rclone-secret
    name: default
    replicas: 1